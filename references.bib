@article{amrheinInferentialStatisticsDescriptive2019,
  title = {Inferential {{Statistics}} as {{Descriptive Statistics}}: {{There Is No Replication Crisis}} If {{We Don}}'t {{Expect Replication}}},
  shorttitle = {Inferential {{Statistics}} as {{Descriptive Statistics}}},
  author = {Amrhein, Valentin and Trafimow, David and Greenland, Sander},
  year = {2019},
  month = mar,
  journal = {The American Statistician},
  volume = {73},
  number = {sup1},
  pages = {262--270},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1543137},
  urldate = {2022-10-05},
  abstract = {Statistical inference often fails to replicate. One reason is that many results may be selected for drawing inference because some threshold of a statistic like the P-value was crossed, leading to biased reported effect sizes. Nonetheless, considerable non-replication is to be expected even without selective reporting, and generalizations from single studies are rarely if ever warranted. Honestly reported results must vary from replication to replication because of varying assumption violations and random variation; excessive agreement itself would suggest deeper problems, such as failure to publish results in conflict with group expectations or desires. A general perception of a ``replication crisis'' may thus reflect failure to recognize that statistical tests not only test hypotheses, but countless assumptions and the entire environment in which research takes place. Because of all the uncertain and unknown assumptions that underpin statistical inferences, we should treat inferential statistics as highly unstable local descriptions of relations between assumptions and data, rather than as providing generalizable inferences about hypotheses or models. And that means we should treat statistical results as being much more incomplete and uncertain than is currently the norm. Acknowledging this uncertainty could help reduce the allure of selective reporting: Since a small P-value could be large in a replication study, and a large P-value could be small, there is simply no need to selectively report studies based on statistical results. Rather than focusing our study reports on uncertain conclusions, we should thus focus on describing accurately how the study was conducted, what problems occurred, what data were obtained, what analysis methods were used and why, and what output those methods produced.},
  keywords = {Auxiliary hypotheses,Confidence interval,Hypothesis test,P-value,Posterior probability,Replication,Selective reporting,Significance test,Statistical model,Unreplicable research},
  file = {C:\Users\james\Zotero\storage\GPJHZUMZ\Amrhein et al. - 2019 - Inferential Statistics as Descriptive Statistics .pdf}
}

@article{amrheinScientistsRiseStatistical2019,
  title = {Scientists Rise up against Statistical Significance},
  author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
  year = {2019},
  month = mar,
  journal = {Nature},
  volume = {567},
  number = {7748},
  pages = {305--307},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-019-00857-9},
  urldate = {2022-10-05},
  abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
  copyright = {2021 Nature},
  langid = {english},
  keywords = {Research data,Research management},
  annotation = {Bandiera\_abtest: a Cg\_type: Comment Subject\_term: Research data, Research management},
  file = {C\:\\Users\\james\\Zotero\\storage\\6H2GHXJ9\\Amrhein et al. - 2019 - Scientists rise up against statistical significanc.pdf;C\:\\Users\\james\\Zotero\\storage\\GPSJZBM6\\d41586-019-00857-9.html}
}

@misc{arel-bundockMarginaleffectsMarginalEffects2022,
  title = {Marginaleffects: {{Marginal Effects}}, {{Marginal Means}}, {{Predictions}}, and {{Contrasts}}},
  shorttitle = {Marginaleffects},
  author = {{Arel-Bundock}, Vincent and Diniz, Marcio Augusto and Greifer, Noah},
  year = {2022},
  month = nov,
  urldate = {2022-11-04},
  abstract = {Compute and plot adjusted predictions, contrasts, marginal effects, and marginal means for over 70 classes of statistical models in R. Conduct linear and non-linear hypothesis tests using the delta method.},
  copyright = {GPL ({$\geq$} 3)},
  keywords = {CausalInference,Econometrics,MixedModels}
}

@misc{batesLme4LinearMixedEffects2023,
  title = {Lme4: {{Linear Mixed-Effects Models}} Using '{{Eigen}}' and {{S4}}},
  shorttitle = {Lme4},
  author = {Bates, Douglas and Maechler, Martin and Bolker [aut, Ben and {cre} and Walker, Steven and Christensen, Rune Haubo Bojesen and Singmann, Henrik and Dai, Bin and Scheipl, Fabian and Grothendieck, Gabor and Green, Peter and Fox, John and Bauer, Alexander and copyright on {simulate.formula)}, Pavel N. Krivitsky (shared},
  year = {2023},
  month = jul,
  urldate = {2023-08-17},
  abstract = {Fit linear and generalized linear mixed-effects models. The models and their components are represented using S4 classes and methods. The core computational algorithms are implemented using the 'Eigen' C++ library for numerical linear algebra and 'RcppEigen' "glue".},
  copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords = {Econometrics,Environmetrics,MixedModels,Psychometrics,SpatioTemporal}
}

@article{bolgerCausalProcessesPsychology2019,
  title = {Causal Processes in Psychology Are Heterogeneous},
  author = {Bolger, Niall and Zee, Katherine S. and {Rossignac-Milon}, Maya and Hassin, Ran R.},
  year = {2019},
  journal = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {4},
  pages = {601--618},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2222},
  doi = {10.1037/xge0000558},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Experimental Methods,Experimental Psychology,Experimenters,Homogeneity of Variance,Models,Repeated Measures,Theory Formulation},
  file = {C:\Users\james\Zotero\storage\DI56KRII\doiLanding.html}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  month = aug,
  journal = {Journal of Statistical Software},
  volume = {80},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  urldate = {2023-07-27},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit  -  among others  -  linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  copyright = {Copyright (c) 2017 Paul-Christian B{\"u}rkner},
  langid = {english},
  keywords = {Bayesian inference,MCMC,multilevel model,ordinal data,R,Stan},
  file = {C:\Users\james\Zotero\storage\JLWNDQQH\BÃ¼rkner - 2017 - brms An R Package for Bayesian Multilevel Models .pdf}
}

@misc{caldwellSimplyAgreeFlexibleRobust2022a,
  title = {{{SimplyAgree}}: {{Flexible}} and {{Robust Agreement}} and {{Reliability Analyses}}},
  shorttitle = {{{SimplyAgree}}},
  author = {Caldwell, Aaron},
  year = {2022},
  month = dec,
  urldate = {2024-02-18},
  abstract = {Reliability and agreement analyses often have limited software support. Therefore, this package was created to make agreement and reliability analyses easier for the average researcher. The functions within this package include simple tests of agreement, agreement analysis for nested and replicate data, and provide robust analyses of reliability. In addition, this package contains a set of functions to help when planning studies looking to assess measurement agreement. For robust analyses of agreement, limits of agreement through a bootstrap method can also be calculated.},
  copyright = {GPL ({$\geq$} 3)}
}

@article{cummingNewStatisticsWhy2014,
  title = {The {{New Statistics}}: {{Why}} and {{How}}},
  shorttitle = {The {{New Statistics}}},
  author = {Cumming, Geoff},
  year = {2014},
  month = jan,
  journal = {Psychological Science},
  volume = {25},
  number = {1},
  pages = {7--29},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797613504966},
  urldate = {2022-10-05},
  abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
  langid = {english},
  file = {C:\Users\james\Zotero\storage\V346TNH8\Cumming - 2014 - The New Statistics Why and How.pdf}
}

@article{jamnickManipulatingGradedExercise2018,
  title = {Manipulating Graded Exercise Test Variables Affects the Validity of the Lactate Threshold and {{V}}{\textperiodcentered}{{O2peak}}},
  author = {Jamnick, Nicholas A. and Botella, Javier and Pyne, David B. and Bishop, David J.},
  year = {2018},
  month = jul,
  journal = {PLOS ONE},
  volume = {13},
  number = {7},
  pages = {e0199794},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0199794},
  urldate = {2024-02-18},
  abstract = {Background To determine the validity of the lactate threshold (LT) and maximal oxygen uptake (V{\textperiodcentered}O2max) determined during graded exercise test (GXT) of different durations and using different LT calculations. Trained male cyclists (n = 17) completed five GXTs of varying stage length (1, 3, 4, 7 and 10 min) to establish the LT, and a series of 30-min constant power bouts to establish the maximal lactate steady state (MLSS). V{\textperiodcentered}O2 was assessed during each GXT and a subsequent verification exhaustive bout (VEB), and 14 different LTs were calculated from four of the GXTs (3, 4, 7 and 10 min){\textemdash}yielding a total 56 LTs. Agreement was assessed between the highest V{\textperiodcentered}O2 measured during each GXT (V{\textperiodcentered}O2peak) as well as between each LT and MLSS. V{\textperiodcentered}O2peak and LT data were analysed using mean difference (MD) and intraclass correlation (ICC). Results The V{\textperiodcentered}O2peak value from GXT1 was 61.0 {$\pm$} 5.3 mL.kg-1.min-1 and the peak power 420 {$\pm$} 55 W (mean {$\pm$} SD). The power at the MLSS was 264 {$\pm$} 39 W. V{\textperiodcentered}O2peak from GXT3, 4, 7, 10 underestimated V{\textperiodcentered}O2peak by {\textasciitilde}1{\textendash}5 mL.kg-1.min-1. Many of the traditional LT methods were not valid and a newly developed Modified Dmax method derived from GXT4 provided the most valid estimate of the MLSS (MD = 1.1 W; ICC = 0.96). Conclusion The data highlight how GXT protocol design and data analysis influence the determination of both V{\textperiodcentered}O2peak and LT. It is also apparent that V{\textperiodcentered}O2max and LT cannot be determined in a single GXT, even with the inclusion of a VEB.},
  langid = {english},
  keywords = {Blood,Curve fitting,Exercise,Government laboratories,Oxygen,Polynomials,Respiration,Statistics},
  file = {C:\Users\james\Zotero\storage\9W88WQXI\Jamnick et al. - 2018 - Manipulating graded exercise test variables affect.pdf}
}

@article{kassBayesFactors1995,
  title = {Bayes {{Factors}}},
  author = {Kass, Robert E. and Raftery, Adrian E.},
  year = {1995},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {90},
  number = {430},
  pages = {773--795},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1995.10476572},
  urldate = {2023-08-17},
  abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: {\textbullet} From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory. {\textbullet} Bayes factors offer a way of evaluating evidence in favor of a null hypothesis. {\textbullet} Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis. {\textbullet} Bayes factors are very general and do not require alternative models to be nested. {\textbullet} Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods. {\textbullet} In ``nonstandard'' statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests. {\textbullet} The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions. {\textbullet} When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty. {\textbullet} Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large. {\textbullet} Bayes factors are useful for guiding an evolutionary model-building process. {\textbullet} It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used.},
  keywords = {Bayesian hypothesis tests,BIC,Importance sampling,Laplace method,Markov chain Monte Carlo,Model selection,Monte Carlo integration,Posterior model probabilities,Posterior odds,Quadrature,Schwarz criterion,Sensitivity analysis,Strength of evidence}
}

@misc{kayTidybayesTidyData2022,
  title = {Tidybayes: {{Tidy Data}} and '{{Geoms}}' for {{Bayesian Models}}},
  shorttitle = {Tidybayes},
  author = {Kay, Matthew and Mastny, Timothy},
  year = {2022},
  month = jan,
  urldate = {2022-10-05},
  abstract = {Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models ('JAGS', 'Stan', 'rstanarm', 'brms', 'MCMCglmm', 'coda', ...) in a tidy data format. Functions are provided to help extract tidy data frames of draws from Bayesian models and that generate point summaries and intervals in a tidy format. In addition, 'ggplot2' 'geoms' and 'stats' are provided for common visualization primitives like points with multiple uncertainty intervals, eye plots (intervals plus densities), and fit curves with multiple, arbitrary uncertainty bands.},
  copyright = {GPL ({$\geq$} 3)}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  urldate = {2022-10-05},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  keywords = {Bayes factor,Bayesian inference,Confidence interval,Credible interval,Effect size,Equivalence testing,Highest density interval,Meta-analysis,Null hypothesis significance testing,Power analysis,Randomized controlled trial,Region of practical equivalence},
  file = {C:\Users\james\Zotero\storage\ZC6EX7YU\Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf}
}

@misc{ludecke@strengejackePerformanceAssessmentRegression2024,
  title = {Performance: {{Assessment}} of {{Regression Models Performance}}},
  shorttitle = {Performance},
  author = {L{\"u}decke  (@strengejacke), Daniel and Makowski  (@Dom\_Makowski), Dominique and {Ben-Shachar  (@mattansb)}, Mattan S. and Patil  (@patilindrajeets), Indrajeet and Waggoner, Philip and Wiernik  (@bmwiernik), Brenton M. and Th{\'e}riault  (@rempsyc), R{\'e}mi and {Arel-Bundock}, Vincent and Jullum, Martin and {gjo11} and Bacher, Etienne},
  year = {2024},
  month = feb,
  urldate = {2024-02-18},
  abstract = {Utilities for computing measures to assess model quality, which are not directly provided by R's 'base' or 'stats' packages. These include e.g. measures like r-squared, intraclass correlation coefficient (Nakagawa, Johnson \& Schielzeth (2017) {$<$}doi:10.1098/rsif.2017.0213{$>$}), root mean squared error or functions to check models for overdispersion, singularity or zero-inflation and more. Functions apply to a large variety of regression models, including generalized linear models, mixed effects models and Bayesian models. References: L{\"u}decke et al. (2021) {$<$}doi:10.21105/joss.03139{$>$}.},
  copyright = {GPL-3},
  keywords = {MixedModels}
}

@misc{maturanaLactaterToolsAnalyzing2023,
  title = {Lactater: {{Tools}} for {{Analyzing Lactate Thresholds}}},
  shorttitle = {Lactater},
  author = {Maturana, Felipe Mattioni},
  year = {2023},
  month = nov,
  urldate = {2024-02-18},
  abstract = {Set of tools for analyzing lactate thresholds from a step incremental test to exhaustion. Easily analyze the methods Log-log, Onset of Blood Lactate Accumulation (OBLA), Baseline plus (Bsln+), Dmax, Lactate Turning Point (LTP), and Lactate / Intensity ratio (LTratio) in cycling, running, or swimming. Beaver WL, Wasserman K, Whipp BJ (1985) {$<$}doi:10.1152/jappl.1985.59.6.1936{$>$}. Heck H, Mader A, Hess G, M{\"u}cke S, M{\"u}ller R, Hollmann W (1985) {$<$}doi:10.1055/s-2008-1025824{$>$}. Kindermann W, Simon G, Keul J (1979) {$<$}doi:10.1007/BF00421101{$>$}. Skinner JS, Mclellan TH (1980) {$<$}doi:10.1080/02701367.1980.10609285{$>$}. Berg A, Jakob E, Lehmann M, Dickhuth HH, Huber G, Keul J (1990) PMID 2408033. Zoladz JA, Rademaker AC, Sargeant AJ (1995) {$<$}doi:10.1113/jphysiol.1995.sp020959{$>$}. Cheng B, Kuipers H, Snyder A, Keizer H, Jeukendrup A, Hesselink M (1992) {$<$}doi:10.1055/s-2007-1021309{$>$}. Bishop D, Jenkins DG, Mackinnon LT (1998) {$<$}doi:10.1097/00005768-199808000-00014{$>$}. Hughson RL, Weisiger KH, Swanson GD (1987) {$<$}doi:10.1152/jappl.1987.62.5.1975{$>$}. Jamnick NA, Botella J, Pyne DB, Bishop DJ (2018) {$<$}doi:10.1371/journal.pone.0199794{$>$}. Hofmann P, Tschakert G (2017) {$<$}doi:10.3389/fphys.2017.00337{$>$}. Hofmann P, Pokan R, von Duvillard SP, Seibert FJ, Zweiker R, Schmid P (1997) {$<$}doi:10.1097/00005768-199706000-00005{$>$}. Pokan R, Hofmann P, Von Duvillard SP, et al. (1997) {$<$}doi:10.1097/00005768-199708000-00009{$>$}. Dickhuth H-H, Yin L, Niess A, et al. (1999) {$<$}doi:10.1055/s-2007-971105{$>$}.},
  copyright = {MIT + file LICENSE}
}

@article{mcshaneAbandonStatisticalSignificance2019,
  title = {Abandon {{Statistical Significance}}},
  author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.},
  year = {2019},
  month = mar,
  journal = {The American Statistician},
  volume = {73},
  number = {sup1},
  pages = {235--245},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1527253},
  urldate = {2022-10-05},
  abstract = {We discuss problems the null hypothesis significance testing (NHST) paradigm poses for replication and more broadly in the biomedical and social sciences as well as how these problems remain unresolved by proposals involving modified p-value thresholds, confidence intervals, and Bayes factors. We then discuss our own proposal, which is to abandon statistical significance. We recommend dropping the NHST paradigm{\textemdash}and the p-value thresholds intrinsic to it{\textemdash}as the default statistical paradigm for research, publication, and discovery in the biomedical and social sciences. Specifically, we propose that the p-value be demoted from its threshold screening role and instead, treated continuously, be considered along with currently subordinate factors (e.g., related prior evidence, plausibility of mechanism, study design and data quality, real world costs and benefits, novelty of finding, and other factors that vary by research domain) as just one among many pieces of evidence. We have no desire to ``ban'' p-values or other purely statistical measures. Rather, we believe that such measures should not be thresholded and that, thresholded or not, they should not take priority over the currently subordinate factors. We also argue that it seldom makes sense to calibrate evidence as a function of p-values or other purely statistical measures. We offer recommendations for how our proposal can be implemented in the scientific publication process as well as in statistical decision making more broadly.},
  keywords = {Null hypothesis significance testing,p-Value,Replication,Sociology of science,Statistical significance},
  file = {C:\Users\james\Zotero\storage\MFCQLH52\McShane et al. - 2019 - Abandon Statistical Significance.pdf}
}

@article{nakagawaCoefficientDeterminationR22017,
  title = {The Coefficient of Determination {{R2}} and Intra-Class Correlation Coefficient from Generalized Linear Mixed-Effects Models Revisited and Expanded},
  author = {Nakagawa, Shinichi and Johnson, Paul C. D. and Schielzeth, Holger},
  year = {2017},
  month = sep,
  journal = {Journal of The Royal Society Interface},
  volume = {14},
  number = {134},
  pages = {20170213},
  publisher = {{Royal Society}},
  doi = {10.1098/rsif.2017.0213},
  urldate = {2023-08-18},
  abstract = {The coefficient of determination R2 quantifies the proportion of variance explained by a statistical model and is an important summary statistic of biological interest. However, estimating R2 for generalized linear mixed models (GLMMs) remains challenging. We have previously introduced a version of R2 that we called  for Poisson and binomial GLMMs, but not for other distributional families. Similarly, we earlier discussed how to estimate intra-class correlation coefficients (ICCs) using Poisson and binomial GLMMs. In this paper, we generalize our methods to all other non-Gaussian distributions, in particular to negative binomial and gamma distributions that are commonly used for modelling biological data. While expanding our approach, we highlight two useful concepts for biologists, Jensen's inequality and the delta method, both of which help us in understanding the properties of GLMMs. Jensen's inequality has important implications for biologically meaningful interpretation of GLMMs, whereas the delta method allows a general derivation of variance associated with non-Gaussian distributions. We also discuss some special considerations for binomial GLMMs with binary or proportion data. We illustrate the implementation of our extension by worked examples from the field of ecology and evolution in the R environment. However, our method can be used across disciplines and regardless of statistical environments.},
  keywords = {goodness of fit,heritability,model fit,reliability analysis,repeatability,variance decomposition},
  file = {C:\Users\james\Zotero\storage\ZSKTEA73\Nakagawa et al. - 2017 - The coefficient of determination R2 and intra-clas.pdf}
}

@misc{pedersenPatchworkComposerPlots2022,
  title = {Patchwork: {{The Composer}} of {{Plots}}},
  shorttitle = {Patchwork},
  author = {Pedersen, Thomas Lin},
  year = {2022},
  month = aug,
  urldate = {2022-10-05},
  abstract = {The 'ggplot2' package provides a strong API for sequentially building up a plot, but does not concern itself with composition of multiple plots. 'patchwork' is a package that expands the API to allow for arbitrarily complex composition of plots by, among others, providing mathematical operators for combining multiple plots. Other packages that try to address this need (but with a different approach) are 'gridExtra' and 'cowplot'.},
  copyright = {MIT + file LICENSE}
}

@article{sterbaAlternativeModelBasedDesignBased2009,
  title = {Alternative {{Model-Based}} and {{Design-Based Frameworks}} for {{Inference From Samples}} to {{Populations}}: {{From Polarization}} to {{Integration}}},
  shorttitle = {Alternative {{Model-Based}} and {{Design-Based Frameworks}} for {{Inference From Samples}} to {{Populations}}},
  author = {Sterba, Sonya K.},
  year = {2009},
  month = nov,
  journal = {Multivariate Behavioral Research},
  volume = {44},
  number = {6},
  pages = {711--740},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1080/00273170903333574},
  urldate = {2024-02-18},
  abstract = {A model-based framework, due originally to R. A. Fisher, and a design-based framework, due originally to J. Neyman, offer alternative mechanisms for inference from samples to populations. We show how these frameworks can utilize different types of samples (nonrandom or random vs. only random) and allow different kinds of inference (descriptive vs. analytic) to different kinds of populations (finite vs. infinite). We describe the extent of each framework's implementation in observational psychology research. After clarifying some important limitations of each framework, we describe how these limitations are overcome by a newer hybrid model/design-based inferential framework. This hybrid framework allows both kinds of inference to both kinds of populations, given a random sample. We illustrate implementation of the hybrid framework using the High School and Beyond data set.},
  pmid = {20411042},
  file = {C:\Users\james\Zotero\storage\QUBQLH8K\Sterba - 2009 - Alternative Model-Based and Design-Based Framework.pdf}
}

@article{wagenmakersPracticalSolutionPervasive2007,
  title = {A Practical Solution to the Pervasive Problems Ofp Values},
  author = {Wagenmakers, Eric-Jan},
  year = {2007},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {5},
  pages = {779--804},
  issn = {1531-5320},
  doi = {10.3758/BF03194105},
  urldate = {2023-08-17},
  abstract = {In the field of psychology, the practice ofp value null-hypothesis testing is as widespread as ever. Despite this popularity, or perhaps because of it, most psychologists are not aware of the statistical peculiarities of thep value procedure. In particular,p values are based on data that were never observed, and these hypothetical data are themselves influenced by subjective intentions. Moreover,p values do not quantify statistical evidence. This article reviews thesep value problems and illustrates each problem with concrete examples. The three problems are familiar to statisticians but may be new to psychologists. A practical solution to thesep value problems is to adopt a model selection perspective and use the Bayesian information criterion (BIC) for statistical inference (Raftery, 1995). The BIC provides an approximation to a Bayesian hypothesis test, does not require the specification of priors, and can be easily calculated from SPSS output.},
  langid = {english},
  keywords = {Bayesian Information Criterion,Null Hypothesis,Posterior Probability,Prior Distribution,Statistical Inference},
  file = {C:\Users\james\Zotero\storage\HFKDRWSD\Wagenmakers - 2007 - A practical solution to the pervasive problems ofp.pdf}
}

@misc{wickhamGgplot2CreateElegant2022,
  title = {Ggplot2: {{Create Elegant Data Visualisations Using}} the {{Grammar}} of {{Graphics}}},
  shorttitle = {Ggplot2},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and RStudio},
  year = {2022},
  month = may,
  urldate = {2022-10-05},
  abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
  copyright = {MIT + file LICENSE},
  keywords = {Spatial,TeachingStatistics}
}
